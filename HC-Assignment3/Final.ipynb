{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "favorite-tunnel",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-04-06T12:51:07.072611Z",
     "iopub.status.busy": "2021-04-06T12:51:07.070920Z",
     "iopub.status.idle": "2021-04-06T12:51:20.714935Z",
     "shell.execute_reply": "2021-04-06T12:51:20.716096Z"
    },
    "papermill": {
     "duration": 13.656978,
     "end_time": "2021-04-06T12:51:20.716513",
     "exception": false,
     "start_time": "2021-04-06T12:51:07.059535",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from torchsummary import summary\n",
    "    \n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms.functional as TF\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ec988a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘saved_image’: File exists\n"
     ]
    }
   ],
   "source": [
    "! mkdir saved_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "492ccc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "def get_pretrained_unetplusplus(input_channel, output_channel):\n",
    "    model = smp.UnetPlusPlus(\n",
    "        encoder_name=\"resnet34\", # Choose the encoder architecture\n",
    "        encoder_weights=\"imagenet\", # Use pre-trained weights from ImageNet\n",
    "        in_channels=input_channel,\n",
    "        classes=output_channel,\n",
    "        activation=None, # No activation function for the final layer\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd286b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class LitsDataset(Dataset):\n",
    "    def __init__(self, csv_file, base_path, type=\"train\", split_ratio=0.2, transform=None, extra_samples=1000):\n",
    "        self.df = pd.read_csv(csv_file)\n",
    "        self.extra = pd.read_csv(csv_file)\n",
    "        self.base_path = base_path\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Filter out liver_mask_empty rows\n",
    "        self.df = self.df[self.df['liver_mask_empty'].isin(['TRUE', True])]\n",
    "        # Add 1000 extra images where liver_mask_empty is False\n",
    "        extra_df = self.extra[self.extra['liver_mask_empty'].isin(['False', False])]\n",
    "        extra_df1 = extra_df.head(extra_samples)\n",
    "        extra_df2 = extra_df.tail(extra_samples)\n",
    "        self.df1 = pd.concat([extra_df1 , self.df], ignore_index=True)\n",
    "        self.df = pd.concat([self.df1, extra_df2], ignore_index=True)\n",
    "\n",
    "        # Train-test split\n",
    "        if type==\"train\":\n",
    "            self.df = self.df.iloc[:int(len(self.df)*(1-split_ratio))]\n",
    "        elif type==\"val\":\n",
    "            self.df = self.df.iloc[int(len(self.df)*(1-split_ratio)):]\n",
    "\n",
    "        self.df['tumor_present'] = self.df['tumor_mask_empty'].apply(lambda x: x not in ['TRUE', True])\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.iloc[index]\n",
    "        img_path = os.path.join(self.base_path, row['filepath'])\n",
    "        image = np.array(Image.open(img_path).convert(\"RGB\"), dtype=np.float32)  # Cast to float32\n",
    "        image = np.transpose(image, (2, 0, 1))\n",
    "\n",
    "        # Load tumor and liver masks\n",
    "        tumor_mask_path = os.path.join(self.base_path, row['tumor_maskpath'])\n",
    "        liver_mask_path = os.path.join(self.base_path, row['liver_maskpath'])\n",
    "        tumor_mask = np.array(Image.open(tumor_mask_path).point(lambda x: x * 255).convert(\"L\"), dtype=np.float32)\n",
    "        liver_mask = np.array(Image.open(liver_mask_path).point(lambda x: x * 255).convert(\"L\"), dtype=np.float32)\n",
    "\n",
    "        # Set mask values\n",
    "        tumor_mask[tumor_mask == 255.0] = 1.0\n",
    "        liver_mask[liver_mask == 255.0] = 1.0\n",
    "\n",
    "        # Create a two-channel mask\n",
    "        mask = np.stack((liver_mask, tumor_mask), axis=0)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            augmentations = self.transform(image=image, mask=mask)\n",
    "            image = augmentations[\"image\"]\n",
    "            mask = augmentations[\"mask\"]\n",
    "\n",
    "        has_tumor = self.df.iloc[index]['tumor_present']\n",
    "\n",
    "        return image, mask, has_tumor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "serious-blond",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-06T12:51:21.655554Z",
     "iopub.status.busy": "2021-04-06T12:51:21.653537Z",
     "iopub.status.idle": "2021-04-06T12:51:21.656309Z",
     "shell.execute_reply": "2021-04-06T12:51:21.656943Z"
    },
    "papermill": {
     "duration": 0.028435,
     "end_time": "2021-04-06T12:51:21.657140",
     "exception": false,
     "start_time": "2021-04-06T12:51:21.628705",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "\n",
    "def save_checkpoint(state, filename=\"my_checkpoint.pth.tar\"):\n",
    "    print(\"=> Saving checkpoint\")\n",
    "    torch.save(state, filename)\n",
    "\n",
    "def load_checkpoint(checkpoint, model):\n",
    "    print(\"=> Loading checkpoint\")\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96c4025",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "\n",
    "def get_loaders(\n",
    "    csv_file,\n",
    "    base_path,\n",
    "    batch_size=8,\n",
    "    train_transform=None,\n",
    "    val_transform=None,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "):\n",
    "\n",
    "    train_ds = LitsDataset(\n",
    "        csv_file=csv_file,\n",
    "        base_path=base_path,\n",
    "        type=\"train\",\n",
    "        transform=train_transform,\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory,\n",
    "        shuffle=True,\n",
    "    )\n",
    "\n",
    "    val_ds = LitsDataset(\n",
    "        csv_file=csv_file,\n",
    "        base_path=base_path,\n",
    "        type=\"val\",\n",
    "        transform=val_transform,\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_ds,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory,\n",
    "        shuffle=True,\n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ffd1fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_val(loader, model, device=\"cuda\"):\n",
    "    num_correct = 0\n",
    "    num_pixels = 0\n",
    "    dice_score_1 = 0\n",
    "    dice_score_2 = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y, has_tumor in loader:  # Updated to include has_tumor\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            preds = torch.sigmoid(model(x))\n",
    "            preds_1 = preds[:, 0, :, :]\n",
    "            preds_2 = preds[:, 1, :, :]\n",
    "            y_1 = y[:, 0, :, :]\n",
    "            y_2 = y[:, 1, :, :]\n",
    "            preds_1 = (preds_1 > 0.5).float()\n",
    "            preds_2 = (preds_2 > 0.5).float()\n",
    "            num_correct += ((preds_1 == y_1) & (preds_2 == y_2)).sum()\n",
    "            num_pixels += torch.numel(y_1)\n",
    "            dice_score_1 += (2 * (preds_1 * y_1).sum()) / ((preds_1 + y_1).sum() + 1e-8)\n",
    "            dice_score_2 += (2 * (preds_2 * y_2).sum()) / ((preds_2 + y_2).sum() + 1e-8)\n",
    "\n",
    "    print(f\"Got {num_correct}/{num_pixels} with acc {num_correct/num_pixels*100:.2f}\")\n",
    "    print(f\"Channel 1 Dice score: {dice_score_1/len(loader)}\")\n",
    "    print(f\"Channel 2 Dice score: {dice_score_2/len(loader)}\")\n",
    "    print(f\"Average Dice score: {(dice_score_1 + dice_score_2) / (2 * len(loader))}\")\n",
    "    model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9484a931",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import directed_hausdorff\n",
    "def check_accuracy(loader, model, device=\"cuda\"):\n",
    "    num_correct = 0\n",
    "    num_pixels = 0\n",
    "    dice_score_1 = 0\n",
    "    dice_score_2 = 0\n",
    "    jaccard_score_1 = 0\n",
    "    jaccard_score_2 = 0\n",
    "    precision_1 = 0\n",
    "    precision_2 = 0\n",
    "    recall_1 = 0\n",
    "    recall_2 = 0\n",
    "    model.eval()\n",
    "    hausdorff_distance_1 = 0\n",
    "    hausdorff_distance_2 = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y , has_tumor in loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            preds = torch.sigmoid(model(x))\n",
    "            preds_1 = preds[:, 0, :, :]\n",
    "            preds_2 = preds[:, 1, :, :]\n",
    "            y_1 = y[:, 0, :, :]\n",
    "            y_2 = y[:, 1, :, :]\n",
    "            preds_1 = (preds_1 > 0.5).float()\n",
    "            preds_2 = (preds_2 > 0.5).float()\n",
    "\n",
    "            intersection_1 = preds_1 * y_1\n",
    "            intersection_2 = preds_2 * y_2\n",
    "\n",
    "            num_correct += (intersection_1.sum() + intersection_2.sum())\n",
    "            num_pixels += (y_1.sum() + y_2.sum())\n",
    "\n",
    "            dice_score_1 += (2 * intersection_1.sum()) / (preds_1.sum() + y_1.sum() + 1e-8)\n",
    "            dice_score_2 += (2 * intersection_2.sum()) / (preds_2.sum() + y_2.sum() + 1e-8)\n",
    "\n",
    "            union_1 = preds_1 + y_1 - intersection_1\n",
    "            union_2 = preds_2 + y_2 - intersection_2\n",
    "            jaccard_score_1 += intersection_1.sum() / (union_1.sum() + 1e-8)\n",
    "            jaccard_score_2 += intersection_2.sum() / (union_2.sum() + 1e-8)\n",
    "\n",
    "            precision_1 += intersection_1.sum() / (preds_1.sum() + 1e-8)\n",
    "            precision_2 += intersection_2.sum() / (preds_2.sum() + 1e-8)\n",
    "            recall_1 += intersection_1.sum() / (y_1.sum() + 1e-8)\n",
    "            recall_2 += intersection_2.sum() / (y_2.sum() + 1e-8)\n",
    "            for i in range(preds_1.shape[0]):\n",
    "                y_np_1 = y_1[i].cpu().numpy()\n",
    "                preds_np_1 = preds_1[i].cpu().numpy()\n",
    "                y_np_2 = y_2[i].cpu().numpy()\n",
    "                preds_np_2 = preds_2[i].cpu().numpy()\n",
    "                \n",
    "                hd1 = directed_hausdorff(y_np_1, preds_np_1)[0]\n",
    "                hd2 = directed_hausdorff(y_np_2, preds_np_2)[0]\n",
    "                \n",
    "                hausdorff_distance_1 += hd1\n",
    "                hausdorff_distance_2 += hd2\n",
    "\n",
    "    n = len(loader)\n",
    "    print(f\"Got {num_correct}/{num_pixels} with acc {num_correct/num_pixels*100:.2f}\")\n",
    "    print(f\"Channel 1 Dice score: {dice_score_1/n}\")\n",
    "    print(f\"Channel 2 Dice score: {dice_score_2/n}\")\n",
    "    print(f\"Average Dice score: {(dice_score_1 + dice_score_2) / (2 * n)}\")\n",
    "    print(f\"Channel 1 Jaccard score: {jaccard_score_1/n}\")\n",
    "    print(f\"Channel 2 Jaccard score: {jaccard_score_2/n}\")\n",
    "    print(f\"Average Jaccard score: {(jaccard_score_1 + jaccard_score_2) / (2 * n)}\")\n",
    "    print(f\"Channel 1 Precision: {precision_1/n}\")\n",
    "    print(f\"Channel 2 Precision: {precision_2/n}\")\n",
    "    print(f\"Average Precision: {(precision_1 + precision_2) / (2 * n)}\")\n",
    "    print(f\"Channel 1 Recall: {recall_1/n}\")\n",
    "    print(f\"Channel 2 Recall: {recall_2/n}\")\n",
    "    print(f\"Average Recall: {(recall_1 + recall_2) / (2 * n)}\")\n",
    "    print(f\"Channel 1 F1-score: {2 * (precision_1 * recall_1) / (precision_1 + recall_1 + 1e-8)/n}\")\n",
    "    print(f\"Channel 2 F1-score: {2 * (precision_2 * recall_2) / (precision_2 + recall_2 + 1e-8)/n}\")\n",
    "    print(f\"Average F1-score: {(2 * (precision_1 * recall_1) + 2 * (precision_2 * recall_2)) / (precision_1 + recall_1 + precision_2 + recall_2 + 1e-8)/n}\")\n",
    "    n = len(loader) * x.shape[0]\n",
    "    print(f\"Channel 1 Hausdorff distance: {hausdorff_distance_1/n}\")\n",
    "    print(f\"Channel 2 Hausdorff distance: {hausdorff_distance_2/n}\")\n",
    "    print(f\"Average Hausdorff distance: {(hausdorff_distance_1 + hausdorff_distance_2) / (2 * n)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f5780f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_predictions_as_imgs(loader, model, folder=\"saved_image/\", device=\"cuda\"):\n",
    "    model.eval()\n",
    "    for idx, (x, y, has_tumor) in enumerate(loader):\n",
    "        x = x.to(device=device)\n",
    "        with torch.no_grad():\n",
    "            preds = torch.sigmoid(model(x))\n",
    "            preds = (preds > 0.5).float()\n",
    "\n",
    "        # Save liver masks and predictions\n",
    "        torchvision.utils.save_image(y[:, 0:1, :, :], f\"{folder}/mask_liver_{idx}.png\")\n",
    "        torchvision.utils.save_image(preds[:, 0:1, :, :], f\"{folder}/pred_liver_{idx}.png\")\n",
    "\n",
    "        # Save tumor masks and predictions only if has_tumor is True\n",
    "        if has_tumor.any():\n",
    "            torchvision.utils.save_image(y[:, 1:2, :, :], f\"{folder}/mask_tumor_{idx}.png\")\n",
    "            torchvision.utils.save_image(preds[:, 1:2, :, :], f\"{folder}/pred_tumor_{idx}.png\")\n",
    "\n",
    "    model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "latest-devil",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-06T12:51:21.683026Z",
     "iopub.status.busy": "2021-04-06T12:51:21.681160Z",
     "iopub.status.idle": "2021-04-06T12:51:21.683597Z",
     "shell.execute_reply": "2021-04-06T12:51:21.684017Z"
    },
    "papermill": {
     "duration": 0.01745,
     "end_time": "2021-04-06T12:51:21.684168",
     "exception": false,
     "start_time": "2021-04-06T12:51:21.666718",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# hyperparams\n",
    "lr = 1e-6\n",
    "dev = \"cuda\"\n",
    "batch_size = 16\n",
    "epochs = 10\n",
    "workers= 8\n",
    "img_h = 256\n",
    "img_w = 256\n",
    "pin_mem= True\n",
    "load_model = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "defensive-heading",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-06T12:51:21.712883Z",
     "iopub.status.busy": "2021-04-06T12:51:21.710884Z",
     "iopub.status.idle": "2021-04-06T12:51:21.713492Z",
     "shell.execute_reply": "2021-04-06T12:51:21.713913Z"
    },
    "papermill": {
     "duration": 0.019925,
     "end_time": "2021-04-06T12:51:21.714048",
     "exception": false,
     "start_time": "2021-04-06T12:51:21.694123",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train_fn(loader, model, optimizer, loss_fn, scaler, device):\n",
    "    loop = tqdm(loader)\n",
    "\n",
    "    for batch_idx, (data, targets, has_tumor) in enumerate(loop):\n",
    "        data = data.to(device=device)\n",
    "        targets = targets.float().to(device=device)\n",
    "\n",
    "        # forward\n",
    "        with torch.cuda.amp.autocast():\n",
    "            predictions = model(data)\n",
    "            \n",
    "            # Calculate loss for liver masks (always)\n",
    "            liver_targets = targets[:, 0, :, :]\n",
    "            liver_outputs = predictions[:, 0, :, :]\n",
    "            liver_loss = loss_fn(liver_outputs, liver_targets)\n",
    "\n",
    "            # Calculate loss for tumor masks (only when has_tumor is True)\n",
    "            if has_tumor.any():\n",
    "                tumor_targets = targets[:, 1, :, :]\n",
    "                tumor_outputs = predictions[:, 1, :, :]\n",
    "                tumor_loss = loss_fn(tumor_outputs, tumor_targets)\n",
    "                loss = liver_loss + tumor_loss\n",
    "            else:\n",
    "                loss = liver_loss\n",
    "\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # update tqdm loop\n",
    "        loop.set_postfix(loss=loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "479a51c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_fn(loader, model, device, criterion):\n",
    "    model.eval()\n",
    "    liver_total_loss = 0.0\n",
    "    tumor_total_loss = 0.0\n",
    "    num_samples = 0\n",
    "    num_samples_with_tumor = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            inputs, targets, has_tumor = data\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # Calculate loss for liver masks (always)\n",
    "            liver_targets = targets[:, 0, :, :]\n",
    "            liver_outputs = outputs[:, 0, :, :]\n",
    "            liver_loss = criterion(liver_outputs, liver_targets)\n",
    "            liver_total_loss += liver_loss.item() * inputs.size(0)\n",
    "            \n",
    "            # Calculate loss for tumor masks (only when any item in the batch has a tumor)\n",
    "            if has_tumor.any():\n",
    "                tumor_targets = targets[:, 1, :, :]\n",
    "                tumor_outputs = outputs[:, 1, :, :]\n",
    "                tumor_loss = criterion(tumor_outputs, tumor_targets)\n",
    "                tumor_total_loss += tumor_loss.item() * inputs.size(0)\n",
    "                num_samples_with_tumor += inputs.size(0)\n",
    "            num_samples += inputs.size(0)\n",
    "        \n",
    "        avg_liver_loss = liver_total_loss / num_samples\n",
    "        avg_tumor_loss = tumor_total_loss / num_samples_with_tumor if num_samples_with_tumor > 0 else 0\n",
    "    \n",
    "    return avg_liver_loss, avg_tumor_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "61155873",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.modules.loss import _Loss\n",
    "import torch.nn as nn\n",
    "\n",
    "class WeightedDiceLoss(nn.Module):\n",
    "    def __init__(self, weights, mode='multilabel', eps=1e-7):\n",
    "        super(WeightedDiceLoss, self).__init__()\n",
    "        self.weights = weights\n",
    "        self.mode = mode\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        assert input.size() == target.size(), \"Input and target must have the same size\"\n",
    "        input = torch.sigmoid(input)\n",
    "        \n",
    "        if self.mode == 'multilabel':\n",
    "            weight_map = torch.zeros_like(target)\n",
    "            for i, w in enumerate(self.weights):\n",
    "                weight_map[target == i] = w\n",
    "            intersection = torch.sum(weight_map * input * target)\n",
    "            union = torch.sum(weight_map * (input + target))\n",
    "        else:\n",
    "            intersection = torch.sum(input * target)\n",
    "            union = torch.sum(input + target)\n",
    "\n",
    "        dice = (2 * intersection + self.eps) / (union + self.eps)\n",
    "\n",
    "        return 1 - dice\n",
    "weights = torch.tensor([0.5, 5]).to(dev)  # Give more weight to white pixels (class 1) and less to black pixels (class 0)\n",
    "loss_fn = WeightedDiceLoss(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d75214",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = A.Compose(\n",
    "    [\n",
    "        A.Resize(height=img_h, width=img_w),\n",
    "        A.RandomRotate90(),\n",
    "        A.Flip(),\n",
    "        A.Transpose(),\n",
    "        A.OneOf([\n",
    "            A.ElasticTransform(alpha=120, sigma=120 * 0.05, alpha_affine=120 * 0.03),\n",
    "            A.GridDistortion(),\n",
    "            A.OpticalDistortion(distort_limit=2, shift_limit=0.5),\n",
    "        ], p=0.3),\n",
    "        A.Normalize(\n",
    "            mean=[0.0, 0.0, 0.0],\n",
    "            std=[1.0, 1.0, 1.0],\n",
    "            max_pixel_value=255.0,\n",
    "        ),\n",
    "        ToTensorV2(),\n",
    "    ],\n",
    ")\n",
    "\n",
    "val_transforms = A.Compose(\n",
    "    [\n",
    "        A.Resize(height=img_h, width=img_w),\n",
    "        A.Normalize(\n",
    "            mean=[0.0, 0.0, 0.0],\n",
    "            std=[1.0, 1.0, 1.0],\n",
    "            max_pixel_value=255.0,\n",
    "        ),\n",
    "        ToTensorV2(),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "religious-cause",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-06T12:51:21.748520Z",
     "iopub.status.busy": "2021-04-06T12:51:21.743088Z",
     "iopub.status.idle": "2021-04-06T13:23:25.415917Z",
     "shell.execute_reply": "2021-04-06T13:23:25.415330Z"
    },
    "papermill": {
     "duration": 1923.690808,
     "end_time": "2021-04-06T13:23:25.416069",
     "exception": false,
     "start_time": "2021-04-06T12:51:21.725261",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 177/177 [01:34<00:00,  1.88it/s, loss=0.102]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 183102631/185204736 with acc 98.86\n",
      "Channel 1 Dice score: 0.8894341588020325\n",
      "Channel 2 Dice score: 0.7023813128471375\n",
      "Average Dice score: 0.7959077954292297\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 177/177 [01:29<00:00,  1.97it/s, loss=0.0528]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 182783882/185204736 with acc 98.69\n",
      "Channel 1 Dice score: 0.8749814629554749\n",
      "Channel 2 Dice score: 0.7373191714286804\n",
      "Average Dice score: 0.8061503171920776\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 177/177 [01:30<00:00,  1.96it/s, loss=0.0574]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 183000791/185204736 with acc 98.81\n",
      "Channel 1 Dice score: 0.8867737054824829\n",
      "Channel 2 Dice score: 0.6983774900436401\n",
      "Average Dice score: 0.7925755977630615\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 177/177 [01:29<00:00,  1.98it/s, loss=0.0539]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 183863072/185204736 with acc 99.28\n",
      "Channel 1 Dice score: 0.9296245574951172\n",
      "Channel 2 Dice score: 0.7216165661811829\n",
      "Average Dice score: 0.8256205320358276\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 177/177 [01:29<00:00,  1.97it/s, loss=0.0338]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 183926610/185204736 with acc 99.31\n",
      "Channel 1 Dice score: 0.9335380792617798\n",
      "Channel 2 Dice score: 0.7197747230529785\n",
      "Average Dice score: 0.8266564607620239\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 177/177 [01:29<00:00,  1.98it/s, loss=0.0408]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 183649215/185204736 with acc 99.16\n",
      "Channel 1 Dice score: 0.9187515377998352\n",
      "Channel 2 Dice score: 0.7312337160110474\n",
      "Average Dice score: 0.8249926567077637\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 177/177 [01:29<00:00,  1.98it/s, loss=0.0324]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 183834169/185204736 with acc 99.26\n",
      "Channel 1 Dice score: 0.9282012581825256\n",
      "Channel 2 Dice score: 0.7775850296020508\n",
      "Average Dice score: 0.8528931140899658\n",
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 177/177 [01:29<00:00,  1.97it/s, loss=0.0283]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 183701075/185204736 with acc 99.19\n",
      "Channel 1 Dice score: 0.9216225743293762\n",
      "Channel 2 Dice score: 0.7405796051025391\n",
      "Average Dice score: 0.8311010599136353\n",
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 177/177 [01:30<00:00,  1.96it/s, loss=0.0313]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00009: reducing learning rate of group 0 to 5.0000e-05.\n",
      "Got 184001382/185204736 with acc 99.35\n",
      "Channel 1 Dice score: 0.9376035928726196\n",
      "Channel 2 Dice score: 0.7364786863327026\n",
      "Average Dice score: 0.8370411396026611\n",
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 177/177 [01:29<00:00,  1.97it/s, loss=0.0276]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 184025068/185204736 with acc 99.36\n",
      "Channel 1 Dice score: 0.9383623003959656\n",
      "Channel 2 Dice score: 0.7475115060806274\n",
      "Average Dice score: 0.8429368734359741\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_channel = 3\n",
    "output_channel = 2  # Updated from 1 to 2\n",
    "model = get_pretrained_unetplusplus(input_channel, output_channel).to(dev)\n",
    "\n",
    "from segmentation_models_pytorch.losses import DiceLoss\n",
    "#loss_fn = DiceLoss(mode='multilabel')\n",
    "\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=5e-4 ,  weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=2, verbose=True)\n",
    "\n",
    "train_loader, val_loader = get_loaders(\n",
    "    csv_file=\"/apps/local/shared/HC701/assessment/assignment_3/data/hc701_lits_train.csv\",\n",
    "    base_path=\"/apps/local/shared/HC701/assessment/assignment_3/data/\",\n",
    "    batch_size=64,\n",
    "    train_transform=None,\n",
    "    val_transform=None,\n",
    ")\n",
    "\n",
    "#check_accuracy(val_loader, model, device=dev)\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "# test_accuracy(test_loader, model, device=dev)\n",
    "# check_accuracy(val_loader, model, device=dev)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(epoch)\n",
    "    train_fn(train_loader, model, optimizer, loss_fn, scaler, device=dev)\n",
    "    val_loss = eval_fn(val_loader, model, device=dev, criterion=loss_fn)\n",
    "    avg_liver_loss, avg_tumor_loss = eval_fn(val_loader, model, device=dev, criterion=loss_fn)\n",
    "    avg_loss = avg_liver_loss*0.1 + avg_tumor_loss*0.9\n",
    "    scheduler.step(avg_loss)\n",
    "\n",
    "    checkpoint = {\n",
    "        \"state_dict\": model.state_dict(),\n",
    "        \"optimizer\":optimizer.state_dict(),\n",
    "    }\n",
    "    # check_accuracy(test_loader, model, device=dev)\n",
    "    # check_accuracy(val_loader, model, device=dev)\n",
    "    check_val(val_loader, model, device=dev)\n",
    "\n",
    "    save_predictions_as_imgs(val_loader, model, folder=\"saved_image/\", device=dev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5227d6d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b50d805e",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ba73ed58",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitsTestDataset(Dataset):\n",
    "    def __init__(self, csv_file, base_path, transform=None):\n",
    "        self.df = pd.read_csv(csv_file)\n",
    "        self.base_path = base_path\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.iloc[index]\n",
    "        img_path = os.path.join(self.base_path, row['filepath'])\n",
    "        image = np.array(Image.open(img_path).convert(\"RGB\"), dtype=np.float32)  # Cast to float32\n",
    "        image = np.transpose(image, (2, 0, 1))\n",
    "\n",
    "        # Load tumor and liver masks\n",
    "        tumor_mask_path = os.path.join(self.base_path, row['tumor_maskpath'])\n",
    "        liver_mask_path = os.path.join(self.base_path, row['liver_maskpath'])\n",
    "        tumor_mask = np.array(Image.open(tumor_mask_path).point(lambda x: x * 255).convert(\"L\"), dtype=np.float32)\n",
    "        liver_mask = np.array(Image.open(liver_mask_path).point(lambda x: x * 255).convert(\"L\"), dtype=np.float32)\n",
    "\n",
    "        # Set mask values\n",
    "        tumor_mask[tumor_mask == 255.0] = 1.0\n",
    "        liver_mask[liver_mask == 255.0] = 1.0\n",
    "\n",
    "        # Create a two-channel mask\n",
    "        mask = np.stack((liver_mask, tumor_mask), axis=0)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            augmentations = self.transform(image=image, mask=mask)\n",
    "            image = augmentations[\"image\"]\n",
    "            mask = augmentations[\"mask\"]\n",
    "\n",
    "        return image, mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eb8d03c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loaders(\n",
    "    csv_file,\n",
    "    base_path,\n",
    "    batch_size=4,\n",
    "    test_transform=None,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    "):\n",
    "    test_ds = LitsTestDataset(\n",
    "    csv_file=csv_file,\n",
    "    base_path=base_path,\n",
    "    transform=test_transform,\n",
    "    )\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        test_ds,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory,\n",
    "        shuffle=False,\n",
    "    )\n",
    "\n",
    "    return test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "37ca401e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = test_loaders(\n",
    "    csv_file=\"/apps/local/shared/HC701/assessment/assignment_3/data/hc701_lits_test.csv\",\n",
    "    base_path=\"/apps/local/shared/HC701/assessment/assignment_3/data/\",\n",
    "    batch_size=16,\n",
    "    test_transform=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2a93f661",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import directed_hausdorff\n",
    "def test_accuracy(loader, model, device=\"cuda\"):\n",
    "    num_correct = 0\n",
    "    num_pixels = 0\n",
    "    dice_score_1 = 0\n",
    "    dice_score_2 = 0\n",
    "    jaccard_score_1 = 0\n",
    "    jaccard_score_2 = 0\n",
    "    precision_1 = 0\n",
    "    precision_2 = 0\n",
    "    recall_1 = 0\n",
    "    recall_2 = 0\n",
    "    model.eval()\n",
    "    hausdorff_distance_1 = 0\n",
    "    hausdorff_distance_2 = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            preds = torch.sigmoid(model(x))\n",
    "            preds_1 = preds[:, 0, :, :]\n",
    "            preds_2 = preds[:, 1, :, :]\n",
    "            y_1 = y[:, 0, :, :]\n",
    "            y_2 = y[:, 1, :, :]\n",
    "            preds_1 = (preds_1 > 0.5).float()\n",
    "            preds_2 = (preds_2 > 0.5).float()\n",
    "\n",
    "            intersection_1 = preds_1 * y_1\n",
    "            intersection_2 = preds_2 * y_2\n",
    "\n",
    "            num_correct += (intersection_1.sum() + intersection_2.sum())\n",
    "            num_pixels += (y_1.sum() + y_2.sum())\n",
    "\n",
    "            dice_score_1 += (2 * intersection_1.sum()) / (preds_1.sum() + y_1.sum() + 1e-8)\n",
    "            dice_score_2 += (2 * intersection_2.sum()) / (preds_2.sum() + y_2.sum() + 1e-8)\n",
    "\n",
    "            union_1 = preds_1 + y_1 - intersection_1\n",
    "            union_2 = preds_2 + y_2 - intersection_2\n",
    "            jaccard_score_1 += intersection_1.sum() / (union_1.sum() + 1e-8)\n",
    "            jaccard_score_2 += intersection_2.sum() / (union_2.sum() + 1e-8)\n",
    "\n",
    "            precision_1 += intersection_1.sum() / (preds_1.sum() + 1e-8)\n",
    "            precision_2 += intersection_2.sum() / (preds_2.sum() + 1e-8)\n",
    "            recall_1 += intersection_1.sum() / (y_1.sum() + 1e-8)\n",
    "            recall_2 += intersection_2.sum() / (y_2.sum() + 1e-8)\n",
    "            for i in range(preds_1.shape[0]):\n",
    "                y_np_1 = y_1[i].cpu().numpy()\n",
    "                preds_np_1 = preds_1[i].cpu().numpy()\n",
    "                y_np_2 = y_2[i].cpu().numpy()\n",
    "                preds_np_2 = preds_2[i].cpu().numpy()\n",
    "                \n",
    "                hd1 = directed_hausdorff(y_np_1, preds_np_1)[0]\n",
    "                hd2 = directed_hausdorff(y_np_2, preds_np_2)[0]\n",
    "                \n",
    "                hausdorff_distance_1 += hd1\n",
    "                hausdorff_distance_2 += hd2\n",
    "\n",
    "    n = len(loader)\n",
    "    print(f\"Got {num_correct}/{num_pixels} with acc {num_correct/num_pixels*100:.2f}\")\n",
    "    print(f\"Channel 1 Dice score: {dice_score_1/n}\")\n",
    "    print(f\"Channel 2 Dice score: {dice_score_2/n}\")\n",
    "    print(f\"Average Dice score: {(dice_score_1 + dice_score_2) / (2 * n)}\")\n",
    "    print(f\"Channel 1 Jaccard score: {jaccard_score_1/n}\")\n",
    "    print(f\"Channel 2 Jaccard score: {jaccard_score_2/n}\")\n",
    "    print(f\"Average Jaccard score: {(jaccard_score_1 + jaccard_score_2) / (2 * n)}\")\n",
    "    print(f\"Channel 1 Precision: {precision_1/n}\")\n",
    "    print(f\"Channel 2 Precision: {precision_2/n}\")\n",
    "    print(f\"Average Precision: {(precision_1 + precision_2) / (2 * n)}\")\n",
    "    print(f\"Channel 1 Recall: {recall_1/n}\")\n",
    "    print(f\"Channel 2 Recall: {recall_2/n}\")\n",
    "    print(f\"Average Recall: {(recall_1 + recall_2) / (2 * n)}\")\n",
    "    print(f\"Channel 1 F1-score: {2 * (precision_1 * recall_1) / (precision_1 + recall_1 + 1e-8)/n}\")\n",
    "    print(f\"Channel 2 F1-score: {2 * (precision_2 * recall_2) / (precision_2 + recall_2 + 1e-8)/n}\")\n",
    "    print(f\"Average F1-score: {(2 * (precision_1 * recall_1) + 2 * (precision_2 * recall_2)) / (precision_1 + recall_1 + precision_2 + recall_2 + 1e-8)/n}\")\n",
    "    n = len(loader) * x.shape[0]\n",
    "    print(f\"Channel 1 Hausdorff distance: {hausdorff_distance_1/n}\")\n",
    "    print(f\"Channel 2 Hausdorff distance: {hausdorff_distance_2/n}\")\n",
    "    print(f\"Average Hausdorff distance: {(hausdorff_distance_1 + hausdorff_distance_2) / (2 * n)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "941d1529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 6738262.0/7501262.0 with acc 89.83\n",
      "Channel 1 Dice score: 0.5945385694503784\n",
      "Channel 2 Dice score: 0.1304144561290741\n",
      "Average Dice score: 0.36247649788856506\n",
      "Channel 1 Jaccard score: 0.5519060492515564\n",
      "Channel 2 Jaccard score: 0.09957405924797058\n",
      "Average Jaccard score: 0.3257400691509247\n",
      "Channel 1 Precision: 0.5725361108779907\n",
      "Channel 2 Precision: 0.2362295538187027\n",
      "Average Precision: 0.4043827950954437\n",
      "Channel 1 Recall: 0.6336069703102112\n",
      "Channel 2 Recall: 0.1109042838215828\n",
      "Average Recall: 0.3722556233406067\n",
      "Channel 1 F1-score: 0.6015254259109497\n",
      "Channel 2 F1-score: 0.15094390511512756\n",
      "Average F1-score: 0.5008273124694824\n",
      "Channel 1 Hausdorff distance: 9.626958103826295\n",
      "Channel 2 Hausdorff distance: 7.44515377091632\n",
      "Average Hausdorff distance: 8.536055937371307\n"
     ]
    }
   ],
   "source": [
    "test_accuracy(test_loader, model, device=dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f414f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Got 47686100.0/47810680.0 with acc 99.74\n",
    "# Channel 1 Dice score: 0.9569560885429382\n",
    "# Channel 2 Dice score: 0.8732251524925232\n",
    "# Average Dice score: 0.9150906205177307\n",
    "# Channel 1 Jaccard score: 0.9174805283546448\n",
    "# Channel 2 Jaccard score: 0.7757256031036377\n",
    "# Average Jaccard score: 0.8466031551361084\n",
    "# Channel 1 Precision: 0.9194984436035156\n",
    "# Channel 2 Precision: 0.7811421751976013\n",
    "# Average Precision: 0.8503202199935913\n",
    "# Channel 1 Recall: 0.9976120591163635\n",
    "# Channel 2 Recall: 0.9910222291946411\n",
    "# Average Recall: 0.9943171739578247\n",
    "# Channel 1 F1-score: 0.956963837146759\n",
    "# Channel 2 F1-score: 0.8736540675163269\n",
    "# Average F1-score: 0.9169454574584961\n",
    "# Channel 1 Hausdorff distance: 4.270770915242545\n",
    "# Channel 2 Hausdorff distance: 1.0659635437510264\n",
    "# Average Hausdorff distance: 2.6683672294967855\n",
    "\n",
    "#val\n",
    "# Got 8331651.0/8540488.0 with acc 97.55\n",
    "# Channel 1 Dice score: 0.9390687346458435\n",
    "# Channel 2 Dice score: 0.7662607431411743\n",
    "# Average Dice score: 0.8526647090911865\n",
    "# Channel 1 Jaccard score: 0.8852533102035522\n",
    "# Channel 2 Jaccard score: 0.6257959008216858\n",
    "# Average Jaccard score: 0.7555246353149414\n",
    "# Channel 1 Precision: 0.8945197463035583\n",
    "# Channel 2 Precision: 0.8221137523651123\n",
    "# Average Precision: 0.8583167195320129\n",
    "# Channel 1 Recall: 0.9883851408958435\n",
    "# Channel 2 Recall: 0.7214162349700928\n",
    "# Average Recall: 0.8549006581306458\n",
    "# Channel 1 F1-score: 0.9391127824783325\n",
    "# Channel 2 F1-score: 0.7684803605079651\n",
    "# Average F1-score: 0.8622468113899231\n",
    "# Channel 1 Hausdorff distance: 12.73293504726183\n",
    "# Channel 2 Hausdorff distance: 3.194581507410058\n",
    "# Average Hausdorff distance: 7.963758277335943\n",
    "\n",
    "# Test\n",
    "# Got 6934455.0/7501262.0 with acc 92.44\n",
    "# Channel 1 Dice score: 0.6926352977752686\n",
    "# Channel 2 Dice score: 0.43730440735816956\n",
    "# Average Dice score: 0.5649698376655579\n",
    "# Channel 1 Jaccard score: 0.5436867475509644\n",
    "# Channel 2 Jaccard score: 0.30633530020713806\n",
    "# Average Jaccard score: 0.42501100897789\n",
    "# Channel 1 Precision: 0.5540947914123535\n",
    "# Channel 2 Precision: 0.38344278931617737\n",
    "# Average Precision: 0.46876880526542664\n",
    "# Channel 1 Recall: 0.969197690486908\n",
    "# Channel 2 Recall: 0.5626262426376343\n",
    "# Average Recall: 0.7659119367599487\n",
    "# Channel 1 F1-score: 0.7050877213478088\n",
    "# Channel 2 F1-score: 0.4560660123825073\n",
    "# Average F1-score: 0.6096818447113037\n",
    "# Channel 1 Hausdorff distance: 10.64208622889427\n",
    "# Channel 2 Hausdorff distance: 6.983804989270198\n",
    "# Average Hausdorff distance: 8.812945609082233"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f67998d28f6fc57a183a22e7a0309b9a80aa8713c373b12cd502dd672f9616c8"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1947.884009,
   "end_time": "2021-04-06T13:23:28.655243",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-04-06T12:51:00.771234",
   "version": "2.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
